---
layout: post
title: BEVerse
thumbnail-img: /assets/../assets/static/Paz9b0sQwofjhJxnJhVcR7Jpnah.png
tags: BEV Perception Multi-view Temporal Multi-task
---

# BEVerse

## Info

> 论文：[https://arxiv.org/abs/2205.09743](https://arxiv.org/abs/2205.09743)
>
> github：[https://github.com/zhangyp15/BEVerse](https://github.com/zhangyp15/BEVerse)

## Abstract

论文提出了 BEVerse，统一的 3D 感知和预测框架

1. 4D BEV 空间下的多视图、多帧特征共享
2. 空间对齐后，spatio-temporal encoder 进行 BEV 特征提取
3. Multi-task decoder 进行联合预测，使用 grid sampler 用于不同 task 的对不同范围和粒度的特征提取
4. 迭代 flow 用于 memory-efficient 的状态预测

## Introduction

自动驾驶任务可以分解为感知、预测、规划控制三个 task，其中：

1. 感知包括动态目标和静态场景
2. 预测任务需要对目标的状态进行推理预测
3. 规划控制根据场景决定和实施精确且安全的驾驶行为

如图所示，传统范式是独立处理每个 task，一个 task 的输出作为另一个 task 的输入，序列化的系统设计相互独立，分解问题

但是误差传播也会在 task 序列中累积，而且序列模型由于重复的特征提取和传播导致计算负载更大

![](../static/JIwFbRSsxozCwyx71HAc5IuPn2d.png)

当前不少研究开始考虑 Lidar 为中心的联合感知和预测，其证明了多任务范式的有效性，考虑到 Lidar 的价格和计算成本，视觉为中心的方法是更好方案

因此，作者引入 BEVerse，用于视觉为中心的联合感知和预测任务，通过多帧融合构建 4D 特征实现目标检测、地图构建、运动预测。并且首次实现任务并行，spatio-temporal 特征融合，最后使在 BEV 空间进行多任务 decoder

1. 为了满足特定任务需求，引入 grid sampler 在 encoder 前进行裁剪和特征变换
2. 当前预测算法 memory-consuming，因此引入迭代 flow 实现高效预测

## Related Works

### 3D Detection

FCOS3D，PGD，DETR3D，PETR，BEVDet，LSS

### Semantic Map Construction

很多方法基于 Lidar-SLAM 生成高精地图，这种方法需要大规模数据收集，长期迭代和人工标注

HDMapNet 是首个基于 Lidar 和 camera 观测使用深度学习进行在线建图的方法，BEVSegFormer 提出了多相机 deformable attention 将 image-view 转化到 BEV 表示并进行语义地图构建，而 BEVerse 将语义建图作为一个子任务，并使用 temporal 信息进行建图

### Model Prediction

场景中道路目标的运动状态对于决策至关重要，不少方法都依赖于 HD map 和检测结果，而 FIERY 实现了第一个感知和预测的 BEV 框架，StretchEBV 对预测引入了延迟变量和和运动残差，BEVerse 相比于 FIERY 有效降低了 memory-consumption

### Multi-Task Learning

FAFNet，MotionNet 基于 Lidar 实现，BEVerse 是第一个纯视觉方案

## Approach

BEVerse 使用$N$时刻的$M$个环视相机、以及自车运动和相机参数作为输入，输出包括当前帧的 3D 检测框，语义地图以及下面连续$T$帧的实例分割和运动预测结果

![](../static/Paz9b0sQwofjhJxnJhVcR7Jpnah.png)

如图所示，BEVerse 包括：

1. Image-view encoder
2. View transformer
3. Spatio-temporal BEV encoder
4. Multi-task decoder

下面将分别描述

### Image-view encoder

假设单张图像的输入为$H \times W \times 3$，image-view encoder 在透视图进行特征提取，并且多相机和多帧的特征共享，鉴于不同任务，特征 encoding 会进行多尺度特征提取，当前使用的 Swin 作为 backbone 提取多维度特征$C_2,~C_3,~C_4,~C_5$，其中，$C_i$表示维度为$\frac{H}{2^i} \times \frac{W}{2^i}$的特征，为了进行有效的特征融合，参考 BEVDet 对$C_5$上采样两次并与$C_4$进行 concat。然后两个特征层用于输出维度为$\frac{H}{16} \times \frac{W}{16} \times C$的特征层$F$，其中$C$表示特征通道。

### View transformer

image-view 到 BEV 空间的 transform 对于学习 3D temporal 特征和多任务预测至关重要。对于每个时刻，view transformer 获得维度为$F \in \mathbb{R}^{M \times H' \times W' \times C}$的多视图特征，输出维度为$G \in \mathbb{R}^{X \times Y \times C}$的 BEV 特征，其中$X$和$Y$表示预定义的网格尺寸。

在 view transfomer 构建中，作者使用的 LSS 策略，多视图特征经过 $1 \times 1$的卷积来预测类别深度分布$F \in \mathbb{R}^{M \times H' \times W' \times D}$，其中$D$表示预定义的深度间隔数，特征图上的每个像素使用深度间隔和相机矩阵参数升到$D$维，生成的稠密深度点云包含$M \times H' \times W' \times D$个点，并通过pillar pooling从而获得维度为$G \in \mathbb{R}^{X \times Y \times C}$ 的 BEV 特征表示。

### Spatio-temporal BEV encoder

view-transformer 之后获得的维度为$G \in \mathbb{R}^{N \times X \times Y \times C}$的 BEV 特征表示，其中$N$表示时间戳的个数，自车运动会导致不同时间戳下坐标系的不对齐，因此首先需要对不同时间戳下的特征进行运动补偿，对齐的 4D tensor 使用 spatio-temporal encoder 提取时空特征，参考 FIERY，BEV encoder 表示为 temporal block 的栈，每个 block 包含 3D 卷积和 global poling 操作，以及 in-between 特征压缩层，最终得到融合时空信息的当前帧 BEV 特征$G_p \in \mathbb{R}^{X \times Y \times C_o}$作为后续多任务的检测器的输出

### Task decoders

获得了时空融合的 BEV 特征$G_p$，BEVerse 对于多任务使用独立并行的 decoder 用于联合感知和预测，每个 task 都包含一个 grid sampler，task encoder 和 task head。首先描述不同 task 下结构相似的 grid sampler 和 task encoder 如下：

#### Grid sampler

不同 task 需要距离和粒度不一样，输入 BEV 特征的空间尺度和分辨率不用直接用于 decoding，比如语义地图学习需要 fine-grained 细粒度的特征，因为交通线在 3D 空间相对较窄，因此 grid sampler 用于裁剪 task-specific 的区域并且通过双线性插值将特征转化为理想的分辨率，在实验中设置 base BEV grid 较大和粗糙以提升效率

#### Task encoder

特征采样后，使用轻量化的 task encoder 对对应区域的 BEV grid 进行特征 encoding，参考 BEVDet，使用 ResNet 的残差块作为基础构建 backbone，并组合多尺度特征，最终输出与输入维度一致的特征到 task head

##### 3D object detection

BEV 空间特征能够统一视觉和 Lidar 的特征，因此直接使用 Lidar 检测头也是可以的，使用单阶段网络 CenterPoint 作为 3D 检测头

##### Semantic map construction

语义地图构建特征使用带 BN 和 ReLU 的两个原生卷积层构成，输出维度为类别数$C_{map}$的语义地图

##### Motion prediction

不同于以上两个任务只考虑当前帧，运动预测需要预测未来的状态。

![](../static/OYVMbXjq3oNZG0xfOctc6GyZneb.png)

如图，FIERY 首先预测未来高斯分布的参数并采样出一个 latent 向量$\phi_t \in \mathbb{R}^L$，其中$L$表示 latent 维度，采样的$\phi_t$空间扩展到维度$\mathbb{R}^{X_{motion} \times Y_{motion} \times L}$，用于初始化未来状态。然后重复使用 convolutional gated recurrent unit 网络和 bottleneck block 用于生成未来的状态$\{s_{t+1},s_{t+2}...s_{t+T}\}$

有两个重要的因子影响着 FIERY 预测模块的有效性：

1. 采样的全局 latent 向量$\phi_t$对每个 BEV 像素共享，无法表示不同目标的不确定性
2. 只是从采样的 latent 向量中来初始化未来预测状态

因此，作者提出 iterative flow 用于未来状态预测。不同于 FIERY，直接预测和采样一个 latent map$\mathbb{R}^{X_{motion} \times Y_{motion} \times L}$，因此不同目标的不确定性可以分别预测，此外，下一时刻的状态通过预测流进行 warp 当前状态得到，天然适用于运动预测和简化学习问题，BEVerse 使用与 FIERY 相同的预测头来获得实例分割和运动状态

## Experiment

### Metrics

#### 3D object detection

参考 nuscene

#### Semantic map construction

语义类别包含 lane divider，pedestrian corssing 和 lane boundary，为了量化结果，对每个类别计算预测和 gt 的 IoU，然后获得均值（mIoU）作为度量

#### Motion prediction

参考 FIERY，使用 IoU 和 VPQ（Future Video Panoptic Quality）评价运动预测的指标，IoU 评价当前和未来帧的分割状态，VPQ 评价预测轨迹的识别和分割结果，VPQ 定义如下：

$$
\begin{aligned}\text{VPQ}&=\sum_{t=0}^T\frac{\sum_{(p_t,q_t)\in TP_t}\text{IoU}(p_t,q_t)}{|TP_t|+\frac12|FP_t|+\frac12|FN_t|}\end{aligned}
$$

其中，$TP_t$、$FP_t$和$FN_t$表示$t$时刻的 TP，FP 和 FN，与 FIERY 类似，计算两种空间下的指标：自车近距离的 $30m \times 30m $和远距离的$100m \times 100m$范围

### Ablation Study

以下分析均使用 BEVerse-Tiny 作为 baseline，使用 BEVerse-Det、BEVerse-Map 和 BEVerse-Motion 表示 BEVerse 的单个 task

#### Temporal information

如图所示，对于 Det 任务，历史帧信息能够提升 2.5 mAP，此外目标的速度和方向预测更加准确；对于 Map 任务，历史帧信息也能带来性能提升

![](../static/RZGTb5aplow7ORxhIzGcZXrlnSf.png)

#### Future prediction

如图所示，对比生成未来预测的不同方法，由于 FIERY 的预测模块包含 ConvGRU 和 Bottleneck block，这两个模块消耗大量 memory 并且阻碍多任务学习，提出了迭代 flow 用于未来状态预测，性能相似但 memory 减半；VPQ 项，同样 BEVerse 更优

![](../static/XIfHbbyfvoozhnxcwcJc4Uy9nMg.png)

#### Multi-task learning

为了分析 multi-task 对每个任务的影响，作者训练了单个 task 的 BEVerse 分析结果：

BEVerse 弱于 BEVerse-Det 和 BEVerse-Map，因为这两个任务分别聚焦于单帧的动态和静态场景理解；但 BEVerse 优于 BEVerse-Motion，因为目标信息有助于提升目标分辨能力，而道路信息有助于为运动估计提供道路先验

最后，多任务有助于降低网络参数量并提升效率

![](../static/FdDPbhFlsojBEWxja7rcd25snjd.png)

#### Data-augmentation strategies

数据增强对 BEV 学习至关重要，尤其是 3D 检测和预测。使用 temporal 数据增强容易导致过拟合并要求更强的正则化以提升性能，只使用 BEV 增强将降低语义 map 性能，可能由于 traffic lane 通常位于特定方向

![](../static/KYoPblGb1oJ4XsxxT5McahNJnVd.png)
